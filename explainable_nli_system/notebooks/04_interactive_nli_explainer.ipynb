{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive NLI Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows you to input a premise and a hypothesis, then receive:\n",
    "1. The NLI model's prediction (entailment, contradiction, or neutral).\n",
    "2. Attention visualizations (full, premise-only, and hypothesis-only self-attention).\n",
    "3. A LIME explanation highlighting words contributing to the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src') # Add src directory to path\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "import numpy as np\n",
    "# matplotlib and seaborn are used by xai_utils.plot_heatmap\n",
    "import lime\n",
    "import lime.lime_text\n",
    "import os\n",
    "\n",
    "from xai_utils import get_lime_predictor, process_model_attentions, plot_heatmap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Fine-tuned Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../src/nli_model/' # Relative path from notebooks/ to src/\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_dir)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_dir, output_attentions=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "label_map = {0: 'entailment', 1: 'contradiction', 2: 'neutral'}\n",
    "class_names = list(label_map.values())\n",
    "\n",
    "print(f\"Model loaded on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = input(\"Enter premise: \")\n",
    "hypothesis = input(\"Enter hypothesis: \")\n",
    "\n",
    "print(f\"\\nPremise: {premise}\")\n",
    "print(f\"Hypothesis: {hypothesis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NLI Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(premise, hypothesis, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "model_attentions_output = outputs.attentions # Store for visualization section\n",
    "\n",
    "predicted_idx = torch.argmax(logits, dim=1).item()\n",
    "predicted_label = label_map[predicted_idx]\n",
    "\n",
    "print(f\"\\nPredicted NLI Label: {predicted_label.upper()} (Class index: {predicted_idx})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process attentions using utility function\n",
    "avg_attentions_np, tokens = process_model_attentions(model_attentions_output, inputs['input_ids'], tokenizer)\n",
    "\n",
    "# Plot combined heatmap using utility function\n",
    "plot_heatmap(avg_attentions_np, tokens, tokens, title='Full Attention Heatmap - Last Layer (Averaged Heads)')\n",
    "\n",
    "# Separated Attention Views\n",
    "try:\n",
    "    sep_idx = tokens.index(tokenizer.sep_token)\n",
    "except ValueError:\n",
    "    print(f\"'{tokenizer.sep_token}' not found in tokens. Cannot generate separated attention views.\")\n",
    "    sep_idx = -1 # Ensure it's defined for logic below\n",
    "\n",
    "if sep_idx != -1 and len(tokens) > 1: # Check if sep_idx is valid and there are enough tokens\n",
    "    # Premise self-attention\n",
    "    premise_tokens = tokens[1:sep_idx] # Exclude [CLS]\n",
    "    premise_avg_attentions = avg_attentions_np[1:sep_idx, 1:sep_idx]\n",
    "    if premise_tokens and premise_avg_attentions.size > 0:\n",
    "        plot_heatmap(premise_avg_attentions, premise_tokens, premise_tokens, title='Premise Self-Attention')\n",
    "    else:\n",
    "        print(\"Not enough tokens to display premise self-attention.\")\n",
    "\n",
    "    # Hypothesis self-attention\n",
    "    hypothesis_tokens = tokens[sep_idx+1:-1] # Exclude [SEP]s\n",
    "    hypothesis_avg_attentions = avg_attentions_np[sep_idx+1:-1, sep_idx+1:-1]\n",
    "    if hypothesis_tokens and hypothesis_avg_attentions.size > 0:\n",
    "        plot_heatmap(hypothesis_avg_attentions, hypothesis_tokens, hypothesis_tokens, title='Hypothesis Self-Attention')\n",
    "    else:\n",
    "        print(\"Not enough tokens to display hypothesis self-attention.\")\n",
    "else:\n",
    "    if sep_idx == -1:\n",
    "        print(\"Skipping separated attention view plots as SEP token was not found.\")\n",
    "    else:\n",
    "        print(\"Skipping separated attention view plots due to insufficient tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LIME Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the LIME predictor function from xai_utils\n",
    "lime_predictor_fn = get_lime_predictor(model, tokenizer, device)\n",
    "\n",
    "text_instance = premise + \" \" + tokenizer.sep_token + \" \" + hypothesis\n",
    "\n",
    "explainer = lime.lime_text.LimeTextExplainer(class_names=class_names, bow=False, random_state=42)\n",
    "\n",
    "print(f\"\\nExplaining LIME for text: '{text_instance}'\")\n",
    "print(f\"Prediction LIME is explaining: {label_map[predicted_idx].upper()}\")\n",
    "\n",
    "lime_explanation = explainer.explain_instance(\n",
    "    text_instance,\n",
    "    lime_predictor_fn, # Use the refactored predictor\n",
    "    num_features=10, \n",
    "    num_samples=500,\n",
    "    labels=(predicted_idx,) # Explain only the predicted class\n",
    ")\n",
    "\n",
    "print(\"\\nDisplaying LIME explanation in notebook (for the predicted class):\")\n",
    "lime_explanation.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- End of Interactive Explanation ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
